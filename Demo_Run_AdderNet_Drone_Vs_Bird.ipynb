{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0ac7e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import resnet20\n",
    "import adder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46008b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mohamad.kassab/Desktop\n"
     ]
    }
   ],
   "source": [
    "cd Desktop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8827fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from resnet20 import resnet20\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader \n",
    "import argparse\n",
    "import math\n",
    "from skimage import io\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18327971",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46b81258",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((100, 100)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "data_set = CustomImageDataset(annotations_file = 'dataset3.csv', img_dir = 'data_dir', transform = transform)\n",
    "\n",
    "\n",
    "data_train, data_test = torch.utils.data.random_split(data_set,[2000,456])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510c3ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Epoch 1, Batch: 1, Loss: 8.119944\n",
      "Test Avg. Loss: 0.938251, Accuracy: 0.504386\n",
      "Train - Epoch 2, Batch: 1, Loss: 0.600813\n",
      "Test Avg. Loss: 0.146088, Accuracy: 0.537281\n",
      "Train - Epoch 3, Batch: 1, Loss: 0.274956\n",
      "Test Avg. Loss: 0.108827, Accuracy: 0.883772\n",
      "Train - Epoch 4, Batch: 1, Loss: 0.127260\n",
      "Test Avg. Loss: 0.080611, Accuracy: 0.953947\n",
      "Train - Epoch 5, Batch: 1, Loss: 0.234333\n",
      "Test Avg. Loss: 0.624193, Accuracy: 0.866228\n",
      "Train - Epoch 6, Batch: 1, Loss: 0.123369\n",
      "Test Avg. Loss: 0.050425, Accuracy: 0.971491\n",
      "Train - Epoch 7, Batch: 1, Loss: 0.068195\n",
      "Test Avg. Loss: 0.083471, Accuracy: 0.938596\n",
      "Train - Epoch 8, Batch: 1, Loss: 0.146113\n",
      "Test Avg. Loss: 0.102507, Accuracy: 0.896930\n",
      "Train - Epoch 9, Batch: 1, Loss: 0.243558\n",
      "Test Avg. Loss: 0.051471, Accuracy: 0.932018\n",
      "Train - Epoch 10, Batch: 1, Loss: 0.163716\n",
      "Test Avg. Loss: 0.042719, Accuracy: 0.958333\n",
      "Train - Epoch 11, Batch: 1, Loss: 0.238487\n",
      "Test Avg. Loss: 0.121432, Accuracy: 0.868421\n",
      "Train - Epoch 12, Batch: 1, Loss: 0.115809\n",
      "Test Avg. Loss: 0.057490, Accuracy: 0.964912\n",
      "Train - Epoch 13, Batch: 1, Loss: 0.007491\n",
      "Test Avg. Loss: 0.032822, Accuracy: 0.960526\n",
      "Train - Epoch 14, Batch: 1, Loss: 0.257899\n",
      "Test Avg. Loss: 0.552790, Accuracy: 0.629386\n",
      "Train - Epoch 15, Batch: 1, Loss: 0.065825\n",
      "Test Avg. Loss: 0.320349, Accuracy: 0.969298\n",
      "Train - Epoch 16, Batch: 1, Loss: 0.267579\n",
      "Test Avg. Loss: 0.316351, Accuracy: 0.984649\n",
      "Train - Epoch 17, Batch: 1, Loss: 0.028772\n",
      "Test Avg. Loss: 0.043809, Accuracy: 0.958333\n",
      "Train - Epoch 18, Batch: 1, Loss: 0.115572\n",
      "Test Avg. Loss: 0.141952, Accuracy: 0.945175\n",
      "Train - Epoch 19, Batch: 1, Loss: 0.072317\n",
      "Test Avg. Loss: 0.299393, Accuracy: 0.771930\n",
      "Train - Epoch 20, Batch: 1, Loss: 0.019016\n",
      "Test Avg. Loss: 0.397455, Accuracy: 0.870614\n",
      "Train - Epoch 21, Batch: 1, Loss: 0.096627\n",
      "Test Avg. Loss: 0.597303, Accuracy: 0.960526\n",
      "Train - Epoch 22, Batch: 1, Loss: 0.028204\n",
      "Test Avg. Loss: 0.354318, Accuracy: 0.901316\n",
      "Train - Epoch 23, Batch: 1, Loss: 0.087340\n",
      "Test Avg. Loss: 0.074205, Accuracy: 0.881579\n",
      "Train - Epoch 24, Batch: 1, Loss: 0.159309\n",
      "Test Avg. Loss: 0.365656, Accuracy: 0.971491\n",
      "Train - Epoch 25, Batch: 1, Loss: 0.044645\n",
      "Test Avg. Loss: 0.117891, Accuracy: 0.936404\n",
      "Train - Epoch 26, Batch: 1, Loss: 0.149977\n",
      "Test Avg. Loss: 0.614789, Accuracy: 0.844298\n",
      "Train - Epoch 27, Batch: 1, Loss: 0.017670\n",
      "Test Avg. Loss: 0.063654, Accuracy: 0.879386\n",
      "Train - Epoch 28, Batch: 1, Loss: 0.230393\n",
      "Test Avg. Loss: 0.028308, Accuracy: 0.962719\n",
      "Train - Epoch 29, Batch: 1, Loss: 0.056816\n",
      "Test Avg. Loss: 0.029367, Accuracy: 0.938596\n",
      "Train - Epoch 30, Batch: 1, Loss: 0.092752\n",
      "Test Avg. Loss: 0.098701, Accuracy: 0.765351\n",
      "Train - Epoch 31, Batch: 1, Loss: 0.050692\n",
      "Test Avg. Loss: 0.115029, Accuracy: 0.831140\n",
      "Train - Epoch 32, Batch: 1, Loss: 0.130590\n",
      "Test Avg. Loss: 0.034892, Accuracy: 0.942982\n",
      "Train - Epoch 33, Batch: 1, Loss: 0.013414\n",
      "Test Avg. Loss: 0.094284, Accuracy: 0.877193\n",
      "Train - Epoch 34, Batch: 1, Loss: 0.127517\n",
      "Test Avg. Loss: 0.034004, Accuracy: 0.938596\n",
      "Train - Epoch 35, Batch: 1, Loss: 0.067848\n",
      "Test Avg. Loss: 0.142010, Accuracy: 0.778509\n",
      "Train - Epoch 36, Batch: 1, Loss: 0.116292\n",
      "Test Avg. Loss: 0.032550, Accuracy: 0.951754\n",
      "Train - Epoch 37, Batch: 1, Loss: 0.196133\n"
     ]
    }
   ],
   "source": [
    "#Copyright (C) 2019. Huawei Technologies Co., Ltd. All rights reserved.\n",
    "\n",
    "#This program is free software; you can redistribute it and/or modify it under the terms of the BSD 3-Clause License.\n",
    "\n",
    "#This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the BSD 3-Clause License for more details.\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='train-addernet')\n",
    "\n",
    "# Basic model parameters.\n",
    "\n",
    "parser.add_argument('output_dir', type=str, default='/cache/models/')\n",
    "args = parser.parse_args(['/home/mohamad.kassab/Desktop'])\n",
    "\n",
    "os.makedirs(args.output_dir, exist_ok=True)  \n",
    "\n",
    "acc = 0\n",
    "acc_best = 0\n",
    "\n",
    "data_train_loader = DataLoader(data_train, batch_size=32, shuffle=True, num_workers=8)\n",
    "data_test_loader = DataLoader(data_test, batch_size=5, num_workers=0)\n",
    "\n",
    "net = resnet20().cuda()\n",
    "criterion = torch.nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"For resnet, the lr starts from 0.1, and is divided by 10 at 80 and 120 epochs\"\"\"\n",
    "    lr = 0.05 * (1+math.cos(float(epoch)/400*math.pi))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "        \n",
    "def train(epoch):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    global cur_batch_win\n",
    "    net.train()\n",
    "    loss_list, batch_list = [], []\n",
    "    for i, (images, labels) in enumerate(data_train_loader):\n",
    "        images, labels = Variable(images).cuda(), Variable(labels).cuda()\n",
    " \n",
    "        optimizer.zero_grad()\n",
    " \n",
    "        output = net(images)\n",
    " \n",
    "        loss = criterion(output, labels)\n",
    " \n",
    "        loss_list.append(loss.data.item())\n",
    "        batch_list.append(i+1)\n",
    " \n",
    "        if i == 1:\n",
    "            print('Train - Epoch %d, Batch: %d, Loss: %f' % (epoch, i, loss.data.item()))\n",
    " \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    " \n",
    " \n",
    "def test():\n",
    "    global acc, acc_best\n",
    "    net.eval()\n",
    "    total_correct = 0\n",
    "    avg_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(data_test_loader):\n",
    "            images, labels = Variable(images).cuda(), Variable(labels).cuda()\n",
    "            output = net(images)\n",
    "            avg_loss += criterion(output, labels).sum()\n",
    "            pred = output.data.max(1)[1]\n",
    "            total_correct += pred.eq(labels.data.view_as(pred)).sum()\n",
    " \n",
    "    avg_loss /= len(data_test)\n",
    "    acc = float(total_correct) / len(data_test)\n",
    "    if acc_best < acc:\n",
    "        acc_best = acc\n",
    "    print('Test Avg. Loss: %f, Accuracy: %f' % (avg_loss.data.item(), acc))\n",
    " \n",
    " \n",
    "def train_and_test(epoch):\n",
    "    train(epoch)\n",
    "    test()\n",
    " \n",
    " \n",
    "def main():\n",
    "    epoch = 50\n",
    "    for e in range(1, epoch):\n",
    "        train_and_test(e)\n",
    "    torch.save(net,args.output_dir + 'addernet')\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2cad3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
